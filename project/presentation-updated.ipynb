{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i97685wCFQ8H"
   },
   "source": [
    "# Model Compression for Uncertainty Estimation using Deep Ensembles\n",
    "\n",
    "## Decomposers Team\n",
    "\n",
    "**Gleb Bazhenov, Saydash Miftakhov, Lina Bashaeva**\n",
    "\n",
    "**Vladislav Trifonov, Alexander Volkov**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u9wFYYAFQ8K"
   },
   "source": [
    "# <ins> Problem Statement</ins>\n",
    "\n",
    "## What?\n",
    "\n",
    " * Investigate how **compression methods** based on tensor decomposition for linear and convolutional layers influence the uncertainty estimation of neural networks in classification task.\n",
    " \n",
    "## Why?\n",
    "\n",
    " * The **problem of uncertainty estimation** is critical for such domains as medical diagnostics and self-driving cars.\n",
    " \n",
    " * The standard approach for estimating the calibration of models and their capability to detect the out-of-distribution (OOD) samples is **Deep Ensembles** [Lakshminarayanan et al., 2017], which requires to construct many independent models.\n",
    " \n",
    " * However, in **memory-constrained applications** the number of parameters needs to be reduced without decrease in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtLCyZROR79R"
   },
   "source": [
    "# <ins> Problem Statement</ins>\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    " * We assume that the compressed models with proper choice of approximation rank **do not lose their performance** and still provide an opportunity for estimating the uncertainty in OOD cases.\n",
    "\n",
    "## Quality Measurement\n",
    "\n",
    " * In order to measure the performance of compressed models in terms of uncertainty we track various properties of predictive distribution of Deep Ensembles, such as **negative log-likelihood** (NLL), **Brier score** (BS) and **entropy**.\n",
    "\n",
    " * Generally, we compare Deep Ensembles with **Monte Carlo Dropout** [Gal & Ghahramani, 2016], providing the uncertainty metrics and the results in **classification accuracy** for both original and compressed models.\n",
    "\n",
    " * All experiments are conducted using MNIST and notMNIST datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7Dmo6oUGuNT"
   },
   "source": [
    "# <ins>Singular Value Decomposition</ins>\n",
    "To compute low-rank approximation, we need to compute **singular value decomposition** (SVD).\n",
    "\n",
    "**Theorem.** Any matrix $A\\in \\mathbb{C}^{n\\times m}$ can be written as a product of three matrices:  \n",
    "\n",
    "$$ A = U \\Sigma V^*, $$\n",
    "\n",
    "where \n",
    "- $U$ is an $n \\times n$ unitary matrix, \n",
    "- $V$ is an $m \\times m$ unitary matrix,\n",
    "- $\\Sigma$ is a diagonal matrix with non-negative elements $\\sigma_1 \\geqslant  \\ldots \\geqslant \\sigma_k$ on the diagonal, where $k = \\min(m, n)$. \n",
    "- Moreover, if $\\text{rank}(A) = r$, then $\\sigma_{r+1} = \\ldots = \\sigma_k = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB-tA9cbFQ8L"
   },
   "source": [
    "# <ins> What is a Tensor</ins>\n",
    "\n",
    "Tensor = multidimensional array:\n",
    "\n",
    "$$\n",
    "A = [A(i_1, \\dots , i_d )], i_k \\in {1, \\dots , n_k }\n",
    "$$\n",
    "\n",
    "Terminology:\n",
    "\n",
    " * *dimensionality* = $d$ (number of indices).\n",
    " * *size* = $n_1 \\times \\dots \\times n_d$ (number of nodes along each axis).\n",
    "\n",
    "Case $d = 1$ is for vector, $d = 2$ is for matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBoAOd0fFQ8L"
   },
   "source": [
    "# <ins> Curse of Dimensionality</ins>\n",
    "\n",
    "Number of elements = $n^d$(exponential in $d$)\n",
    "\n",
    "When $n = 2, d = 100$\n",
    "\n",
    "$$\n",
    "2^{100} > 10^{30} \\text{($\\approx$ 1018 PB of memory).}\n",
    "$$\n",
    "\n",
    "Cannot work with tensors using standard methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cqZachxFQ8M"
   },
   "source": [
    "# <ins>Tensor Rank Decomposition [Hitchcock, 1927]</ins>\n",
    "\n",
    "Recall the rank decomposition for matrices:\n",
    "\n",
    "$$\n",
    "A(i_1, i_2) = \\sum\\limits^r_{\\alpha=1} U(i_1, \\alpha)V(i_2, \\alpha).\n",
    "$$\n",
    "\n",
    "This can be generalized to tensors.\n",
    "\n",
    "Tensor rank decomposition (**canonical decomposition**):\n",
    "\n",
    "$$\n",
    "A(i_1, \\dots , i_d ) = \\sum_{\\alpha=1}^{R} U_1(i_1, \\alpha) \\dots U_d(i_d , \\alpha).\n",
    "$$\n",
    "\n",
    "The minimal possible $R$ is called the (canonical) rank of the tensor $A$.\n",
    "\n",
    "Pros\n",
    " * No curse of dimensionality.\n",
    " \n",
    "Cons\n",
    " * Ill-posed problem [de Silva, Lim, 2008];\n",
    " \n",
    " * Rank $R$ should be known in advance for many methods;\n",
    " \n",
    " * Computation of $R$ is NP-hard [Hillar, Lim, 2013]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8ykrwfHFQ8M"
   },
   "source": [
    "# <ins> Unfolding Matrices: Definition\n",
    "\n",
    "Every tensor $A$ has $d - 1$ **unfolding matrices**:\n",
    "    \n",
    "$$\n",
    "A_k := [A(i_1 \\dots i_k ; i_{k+1} \\dots i_d )],\n",
    "$$\n",
    "    \n",
    "where\n",
    "    \n",
    "$$\n",
    "A(i_1 \\dots i_k ; i_{k+1} \\dots i_d ) := A(i_1, \\dots , i_d).\n",
    "$$\n",
    "    \n",
    "Here $i_1 \\dots i_k$ and $i_{k+1} \\dots i_d$ are row and column (multi)indices; $A_k$ are\n",
    "matrices of size $M_k \\times N_k$ with $$M_k =\\prod^k_{s=1}n_s, N_k = \\prod^d_{s=k+1}n_s.$$\n",
    "\n",
    "This is just a reshape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbYkwyFgFQ8N"
   },
   "source": [
    "# <ins> Unfolding Matrices: Example</ins>\n",
    "\n",
    "Consider $A = [A(i, j, k)]$ given by its elements:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\begin{split}\n",
    "    A(1, 1, 1) = 111, \\quad A(2, 1, 1) = 211,\\\\\n",
    "    A(1, 2, 1) = 121, \\quad A(2, 2, 1) = 221,\\\\\n",
    "    A(1, 1, 2) = 112, \\quad A(2, 1, 2) = 212,\\\\\n",
    "    A(1, 2, 2) = 122, \\quad A(2, 2, 2) = 222.\n",
    "\\end{split}\n",
    "\\end{equation*}$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$A_1 = [A(i; jk)] = \n",
    "\\begin{bmatrix}\n",
    "111 & 121 & 112 & 122 \\\\\n",
    "211 & 221 & 212 & 222\n",
    "\\end{bmatrix},$$\n",
    "\n",
    "$$A_2 = [A(ij; k)] =\n",
    "\\begin{bmatrix}\n",
    "111 & 112\\\\\n",
    "211 & 212\\\\\n",
    "121 & 122\\\\\n",
    "221 & 222\n",
    "\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BFof0vWFQ8N"
   },
   "source": [
    "# <ins>Tensor Train Decomposition: Motivation</ins>\n",
    "\n",
    "Main idea â€” **variable splitting**.\n",
    "\n",
    "Consider a rank decomposition of an unfolding matrix:\n",
    "\n",
    "$$\n",
    "A(i_1i_2; i_3i_4i_5i_6) = \\sum\\limits_{\\alpha_2}U(i_1i_2; \\alpha_2)V(i_3i_4i_5i_6; \\alpha_2).\n",
    "$$\n",
    "\n",
    "On the left: 6-dimensional tensor; on the right: 3- and 5-dimensional.\n",
    "The dimension has reduced! Proceed recursively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFUOlJ81FQ8O"
   },
   "source": [
    "# <ins>Tensor Train Decomposition [Oseledets, 2011]</ins>\n",
    "\n",
    " * TT-format for a tensor A:\n",
    " \n",
    "$$\n",
    "A(i_1, \\dots , i_d ) = \\sum\\limits_{\\alpha_0,\\dots,\\alpha_d}\n",
    "G_1(\\alpha_0, i_1, \\alpha_1)G_2(\\alpha_1, i_2, \\alpha_2)\\dots G_d (\\alpha_d-1, i_d , \\alpha_d ).\n",
    "$$\n",
    "\n",
    " * This can be written compactly as a matrix product:\n",
    " \n",
    "$$\n",
    "A(i_1, \\dots , i_d ) = \\underbrace{G_1[i_1]}_{1\\times r_1}\n",
    "\\underbrace{G_2[i_2]}_{r_1\\times r_2}\n",
    "\\dots \\underbrace{G_d [i_d]}_{r_{d-1}\\times1}\n",
    "$$\n",
    "\n",
    " * Terminology:\n",
    "\n",
    "  - $G_i$: TT-cores (collections of matrices)\n",
    "  - $r_i$: TT-ranks\n",
    "  - $r = \\max r_i$: maximal TT-rank\n",
    "\n",
    " * TT-format uses $O(dnr^2)$ memory to store $O(n^d)$ elements.\n",
    " \n",
    " * Efficient only if the ranks are small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt8G1x-tFQ8O"
   },
   "source": [
    "# <ins>Finding a TT-representation of a Tensor</ins>\n",
    "\n",
    "General ways for building a TT-decomposition of a tensor:\n",
    "\n",
    " * Analytical formulas for the TT-cores.\n",
    " * TT-SVD algorithm [Oseledets, 2011]:\n",
    "\n",
    "  * Exact quasi-optimal method.\n",
    "  *  Suitable only for small tensors (which fit into memory).\n",
    "\n",
    " * Interpolation algorithms: AMEn-cross [Dolgov & Savostyanov, 2013], DMRG [Khoromskij & Oseledets, 2010], TT-cross [Oseledets, 2010]\n",
    "\n",
    "  * Approximate heuristically-based methods.\n",
    "  * Can be applied for large tensors.\n",
    "  * No strong guarantees but work well in practice.\n",
    "\n",
    " * Operations between other tensors in the TT-format: addition, element-wise product etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_x97cxAFQ8P"
   },
   "source": [
    "# <ins> Results: Ensemble of MLPs </ins>\n",
    "\n",
    "    MLP(\n",
    "        (feature_extractor): Sequential(\n",
    "            (0): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (1): Linear(in_features=784, out_features=200, bias=True)\n",
    "            (2): ReLU()\n",
    "            (3): Dropout(p=0.1, inplace=False)\n",
    "            (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (5): Linear(in_features=200, out_features=200, bias=True)\n",
    "            (6): ReLU()\n",
    "            (7): Dropout(p=0.1, inplace=False)\n",
    "            (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (9): Linear(in_features=200, out_features=200, bias=True)\n",
    "            (10): ReLU()\n",
    "            (11): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "        (classifier): Sequential(\n",
    "            (0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (1): Linear(in_features=200, out_features=10, bias=True)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__48HrQOXN51"
   },
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/mlp-metric-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/mlp-metric-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/mc-mlp-entropy-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/mc-mlp-entropy-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/de-mlp-entropy-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/de-mlp-entropy-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: SVD for Ensemble of MLPs </ins>\n",
    "\n",
    "<img src=\"mlp-united/mlp-ratio.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "    CNN(\n",
    "        (feature_extractor): Sequential(\n",
    "            (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "            (2): ReLU()\n",
    "            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "            (6): ReLU()\n",
    "            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "            (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "            (10): ReLU()\n",
    "            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "            (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (13): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "            (14): ReLU()\n",
    "            (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "            (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "            (18): ReLU()\n",
    "            (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        (classifier): Sequential(\n",
    "            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
    "            (2): ReLU()\n",
    "            (3): Dropout(p=0.1, inplace=False)\n",
    "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (5): Linear(in_features=64, out_features=10, bias=True)\n",
    "            (6): ReLU()\n",
    "            (7): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__48HrQOXN51"
   },
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/cnn-metric-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/cnn-metric-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/mc-cnn-entropy-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/mc-cnn-entropy-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/de-cnn-entropy-size.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/de-cnn-entropy-rank.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Results: TT for Ensemble of CNNs </ins>\n",
    "\n",
    "<img src=\"cnn-united/cnn-ratio.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7qlnkHtFQ8P"
   },
   "source": [
    "# <ins> Summary </ins>\n",
    "\n",
    "## Main Results\n",
    "\n",
    " * **reproduce the comparison** of Deep Ensembles and Monte Carlo Dropout,\n",
    " \n",
    " * show the relation between **rank of SVD and TT decompositions** and classification performance,\n",
    " \n",
    " * **experimentally prove** that proper approximation rank still provides an opportunity for estimating the uncertainty in OOD cases.\n",
    " \n",
    "In particular, we show that too intensive compression of model leads to additional uncertainty and does not allow to detect the OOD samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Summary </ins>\n",
    "\n",
    "## Potentian Improvements\n",
    "\n",
    " * perform **fine-tuning** of compressed models,\n",
    " \n",
    " * compare other methods of tensor decomposition (for instance, CP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Appendix: More Advanced Methods for UE </ins>\n",
    "\n",
    " * Prior Networks [Malinin & Gales, 2018]\n",
    " \n",
    " * Evidential Deep Learning [Sensoy et al., 2018]\n",
    " \n",
    " * Ensemble Distribution Distillation [Malinin, Mlodozeniec et al., 2019]\n",
    " \n",
    " * Posterior Network [Charpentier et al., 2020]\n",
    " \n",
    " * and others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "presentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
